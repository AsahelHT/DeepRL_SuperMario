{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d599b662",
   "metadata": {},
   "source": [
    "# üïπÔ∏èüëæ Reinforcement Learning aplicado a *Super Mario Bros* üëæüïπÔ∏è\n",
    "\n",
    "---\n",
    "\n",
    "## Presentaci√≥n de la pr√°ctica\n",
    "\n",
    "Se entrega un **notebook modificado** para facilitar la comprensi√≥n y ejecuci√≥n de la pr√°ctica desarrollada.  \n",
    "Este cuaderno ha sido adaptado eliminando las celdas de los tutoriales de ejemplo y a√±adiendo nuevas secciones para mejorar el flujo de trabajo y el entendimiento del c√≥digo.\n",
    "\n",
    "üöÄ **[Explora el proyecto en GitHub](https://github.com/AsahelHT/DeepRL_SuperMario)**  \n",
    "\n",
    "---\n",
    "\n",
    "## Resultado obtenido\n",
    "\n",
    "<figure style=\"text-align: center; margin-top: 20px;\">\n",
    "  <img src=\"./media/gifs/PPO_CNN_3005_3.gif\" alt=\"Mejor entrenamiento logrado\" width=\"350\">\n",
    "  <figcaption style=\"font-style: italic; color: #555; margin-top: 10px;\">\n",
    "    üèÜ Mejor entrenamiento logrado: <strong>PPO_CNN_3005_3</strong>\n",
    "  </figcaption>\n",
    "</figure>\n",
    "\n",
    "---\n",
    "\n",
    "## Estructura del Notebook\n",
    "\n",
    "El notebook se organiza en **cuatro secciones principales**:\n",
    "\n",
    "1. ‚öôÔ∏è **Configuraci√≥n del entorno**  \n",
    "2. üõ†Ô∏è **Modificaci√≥n y ampliaci√≥n**  \n",
    "3. üß† **Entrenamiento del agente**  \n",
    "4. üìà **Evaluaci√≥n de desempe√±o**\n",
    "\n",
    "Cada secci√≥n incluye comentarios y celdas auxiliares para facilitar la experimentaci√≥n y comprensi√≥n del aprendizaje por refuerzo profundo.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a135ea2",
   "metadata": {},
   "source": [
    "## 1. ‚öôÔ∏è Configuraci√≥n inicial del entorno\n",
    "\n",
    "Para ejecutar correctamente este notebook, se recomienda usar un entorno `conda` o equivalente con:\n",
    "\n",
    "- **Python 3.8**\n",
    "- Todas las dependencias detalladas en el archivo `requirements.txt` incluido con el proyecto\n",
    "\n",
    "Puedes crear el entorno ejecutando:\n",
    "\n",
    "```bash\n",
    "conda create -n mario_rl python=3.8\n",
    "pip install -r requirements.txt\n",
    "\n",
    "```\n",
    "\n",
    "Lo primero es importar las librer√≠as necesarias para ejecutar el entorno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4e2625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "# Gymnasium ofrece diferentes tipos de espacios para definir el espacio de acci√≥n y el espacio de observaci√≥n.\n",
    "# En este caso, usamos Box para definir un espacio de observaci√≥n continuo, y Discrete para un espacio de acci√≥n discreto.\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "\n",
    "# Para modificar el entorno de Gymnasium, usamos la clase Wrapper.\n",
    "# Wrapper es una clase base que permite modificar el comportamiento de un entorno sin cambiar su implementaci√≥n.\n",
    "from gymnasium import Wrapper\n",
    "\n",
    "# Del emulador de NES, importamos el espacio de acci√≥n que emula el joystick.\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "# Importamos el entorno de Super Mario Bros.\n",
    "import gym_super_mario_bros\n",
    "# Como indica la documentacion, el entorno de Super Mario Bros. tiene diferentes espacios de acci√≥n.\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT, RIGHT_ONLY\n",
    "\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack, SubprocVecEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from typing import Callable\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from collections import deque\n",
    "import torch\n",
    "from typing import Callable\n",
    "\n",
    "# Variables de configuraci√≥n\n",
    "# Puedes cambiar el mundo y el nivel para probar diferentes niveles de Super Mario Bros.\n",
    "# Tambi√©n puedes cambiar el tipo de acci√≥n y el n√∫mero de frames apilados.\n",
    "WORLD = 1\n",
    "STAGE = 1\n",
    "ACTION_TYPE = RIGHT_ONLY \n",
    "N_FRAMES_STACK = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16990390",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 2. üõ†Ô∏è Modificaci√≥n y ampliaci√≥n del entorno\n",
    "\n",
    "Se han realizado diversas mejoras sobre el entorno original de entrenamiento con el objetivo de optimizar el rendimiento del agente y adaptar el entorno a las necesidades espec√≠ficas del experimento.\n",
    "\n",
    "<blockquote style=\"border-left: 4px solid #00bcd4; background: #f0faff; padding: 10px; color: #333;\">\n",
    "üîß <strong>Modificaciones aplicadas:</strong>\n",
    "<ul style=\"margin-top: 10px;\">\n",
    "  <li><strong>2.1 Preprocesado de la imagen:</strong> Reducci√≥n de tama√±o, escala de grises y normalizaci√≥n de los fotogramas para facilitar el aprendizaje.</li>\n",
    "  <li><strong>2.2 Personalizaci√≥n de la funci√≥n de recompensa:</strong> Ajustes para incentivar el avance en el escenario y penalizar acciones no productivas.</li>\n",
    "  <li><strong>2.3 Obtenci√≥n de informaci√≥n temporal:</strong> Almacenamiento de estados anteriores para dotar al agente de una noci√≥n de secuencia (frame stacking).</li>\n",
    "  <li><strong>2.4 Creaci√≥n del entorno de entrenamiento:</strong> Se implementa la funci√≥n que permite crear un entorno aplicando todos los Wrappers anteriores.</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2632cf9",
   "metadata": {},
   "source": [
    "### 2.1 Preprocesado de la imagen\n",
    "\n",
    "El primer paso consiste en aplicar un **preprocesado a la imagen** recibida del entorno para reducir su complejidad y hacer m√°s eficiente el aprendizaje del agente.\n",
    "\n",
    "<blockquote style=\"border-left: 4px solid #4CAF50; background: #f9fff9; padding: 10px; color: #333;\">\n",
    "üñºÔ∏è <strong>Operaciones realizadas:</strong>\n",
    "<ul style=\"margin-top: 10px;\">\n",
    "  <li><strong>Conversi√≥n a escala de grises:</strong> elimina el canal de color, conservando √∫nicamente la informaci√≥n relevante.</li>\n",
    "  <li><strong>Reducci√≥n de tama√±o:</strong> disminuye la resoluci√≥n para acortar los tiempos de c√≥mputo y reducir la dimensionalidad.</li>\n",
    "  <li><strong>Normalizaci√≥n:</strong> transforma los valores de p√≠xel al rango <code>[0, 1]</code> para estabilizar el proceso de entrenamiento.</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n",
    "La funci√≥n implementada toma como entrada la **observaci√≥n en crudo** proporcionada por el entorno (una imagen RGB) y devuelve una versi√≥n preprocesada siguiendo los pasos anteriores:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f22bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dimensiones de la imagen procesada\n",
    "HEIGHT = 84\n",
    "WIDTH = 84\n",
    "\n",
    "# Aplica un procesamiento a la imagen del entorno para que sea m√°s f√°cil de manejar.\n",
    "def process_frame(frame):\n",
    "    if frame is not None:\n",
    "        if len(frame.shape) == 3 and frame.shape[2] == 3:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        resized = cv2.resize(frame, (WIDTH, HEIGHT))\n",
    "        normalized = resized / 255.0\n",
    "\n",
    "        return normalized.astype(np.float32)  # Ensure the output is float32\n",
    "    else:\n",
    "        return np.zeros((HEIGHT, WIDTH), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c648ce",
   "metadata": {},
   "source": [
    "Con esto, pasamos de tener una observaci√≥n de dimensiones 3x256x240, a 1xHEIGHTXWIDHT, reduciendo dr√°sticamente nuestra representaci√≥n del estado del mundo de Mario. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb104a6d",
   "metadata": {},
   "source": [
    "### 2.2 Personalizaci√≥n de la funci√≥n de recompensa\n",
    "\n",
    "La funci√≥n de recompensa ha sido dise√±ada para **alinear el comportamiento del agente con los objetivos del juego**, incentivando el progreso hacia la derecha, la rapidez y la supervivencia.\n",
    "\n",
    "<blockquote style=\"border-left: 4px solid #ff9800; background: #fffaf0; padding: 10px; color: #333;\">\n",
    "üéØ <strong>Componentes de la recompensa:</strong>\n",
    "<ul style=\"margin-top: 10px;\">\n",
    "  <li><strong>Progreso horizontal:</strong> se recompensa moverse a la derecha.</li>\n",
    "  <li><strong>Puntuaci√≥n:</strong> se recompensa la obtenci√≥n de puntos.</li>\n",
    "  <li><strong>Muerte del agente:</strong> penalizaci√≥n significativa por perder una vida.</li>\n",
    "  <li><strong>Bandera final:</strong> recompensa alta por completar el nivel.</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n",
    "Esta combinaci√≥n de recompensas y penalizaciones permite guiar el entrenamiento del agente hacia una estrategia **eficiente y segura**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomReward(Wrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(CustomReward, self).__init__(env)\n",
    "        self.observation_space = Box(low=0, high=255, shape=(HEIGHT, WIDTH))\n",
    "        self.action_space = Discrete(env.action_space.n)\n",
    "        self.info = {}\n",
    "        self.prev_x = 40\n",
    "        self.prev_score = 0 \n",
    "        #self.prev_time = None\n",
    "        self.prev_lives = 2\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, trunk, info = self.env.step(action)\n",
    "        self.info = info\n",
    "        processed_img = process_frame(obs)\n",
    "\n",
    "        reward = 0.0\n",
    "\n",
    "        delta_x_reward = 0.0\n",
    "        delta_score_reward = 0.0\n",
    "        flag_reward = 0.0\n",
    "        death_penalty = 0.0\n",
    "\n",
    "        # Penalizacion si muere o no llega a la meta\n",
    "        current_lives = info.get('life', self.prev_lives)\n",
    "        if current_lives < self.prev_lives:\n",
    "            death_penalty -= 50.0  \n",
    "\n",
    "        # Recompensa por avanzar, penalizacion por quedarse quieto\n",
    "        delta_x = info['x_pos'] - self.prev_x\n",
    "        if delta_x > 0:\n",
    "            delta_x_reward += delta_x * 0.1\n",
    "            \n",
    "        # Recompensa si llega a la meta\n",
    "        if info.get('flag_get', False):\n",
    "            flag_reward += 100.0\n",
    "\n",
    "        # Recompensa por incremento en la puntuacion\n",
    "        delta_score = info['score'] - self.prev_score\n",
    "        if delta_score > 0:\n",
    "            delta_score_reward += delta_score * 0.01  \n",
    "\n",
    "        self.prev_lives = current_lives\n",
    "\n",
    "        # Actualizaci√≥n de valores previos\n",
    "        self.prev_x = info['x_pos']\n",
    "        self.prev_score = info['score']  \n",
    "\n",
    "        # Funci√≥n de recompensa \n",
    "        reward = death_penalty + delta_x_reward + flag_reward + delta_score_reward\n",
    "\n",
    "        return processed_img, reward, done, trunk, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "\n",
    "        self.prev_score = 0\n",
    "        self.prev_x = 40\n",
    "        self.prev_lives = 2\n",
    "\n",
    "        obs, info = self.env.reset()\n",
    "        obs = process_frame(obs)\n",
    "        return obs, info\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2472093",
   "metadata": {},
   "source": [
    "### 2.3 Obtenci√≥n de informaci√≥n temporal\n",
    "\n",
    "Para que el agente sea capaz de interpretar el movimiento en el entorno (como la velocidad o direcci√≥n de los objetos), es necesario proporcionarle **informaci√≥n temporal**. Esto se consigue mediante el uso de **wrappers personalizados**.\n",
    "\n",
    "<blockquote style=\"border-left: 4px solid #3f51b5; background: #f4f6ff; padding: 10px; color: #333;\">\n",
    "‚è≥ <strong>Mecanismos implementados:</strong>\n",
    "<ul style=\"margin-top: 10px;\">\n",
    "  <li><strong>Apilamiento de N frames consecutivos:</strong> se almacena una secuencia de <code>N</code> observaciones recientes, dando lugar a un tensor de forma <code>(N, height, width)</code>. Esto permite al agente inferir el movimiento de los elementos en pantalla durante el tiempo.</li>\n",
    "  <li><strong>Repetici√≥n de acciones:</strong> se mantiene la misma acci√≥n durante varios frames consecutivos, mejorando la estabilidad de las decisiones y reduce acciones err√°ticas.</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n",
    "Este enfoque permite simular una memoria visual de corto plazo, **mejorando la capacidad de planificaci√≥n del agente** y facilitando el aprendizaje en entornos din√°micos como *Super Mario Bros*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28a4d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper para apilar frames del entorno.\n",
    "# Esta clase se encargar√° de apilar los frames del entorno para crear un stack de frames.\n",
    "# Esto es √∫til para que el agente pueda ver el movimiento de Mario y aprender a jugar mejor.\n",
    "\n",
    "N_FRAMES = 4\n",
    "REPEAT_ACTION = 4  # N√∫mero de veces que se repetir√° la acci√≥n\n",
    "\n",
    "class CustomStackAndRepeat(Wrapper):\n",
    "    def __init__(self, env, n_frames=N_FRAMES, repeat=REPEAT_ACTION):\n",
    "        super(CustomStackAndRepeat, self).__init__(env)\n",
    "        self._n_frames = n_frames\n",
    "        self.repeat = repeat\n",
    "\n",
    "        # Espacio de observaci√≥n actualizado\n",
    "        self.observation_space = Box(low=0, high=1.0, shape=(self._n_frames, HEIGHT, WIDTH), dtype=np.float32)\n",
    "\n",
    "        # Deque para almacenar los √∫ltimos frames\n",
    "        self.frames = deque(maxlen=n_frames)\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0.0\n",
    "        done = False\n",
    "        trunk = False\n",
    "        info = {}\n",
    "        \n",
    "        for _ in range(self.repeat):\n",
    "            obs, reward, done, trunk, info = self.env.step(action)\n",
    "            processed_obs = process_frame(obs)\n",
    "            self.frames.append(processed_obs)\n",
    "            total_reward += reward\n",
    "            if done or trunk:\n",
    "                break\n",
    "\n",
    "        # Si no hay suficientes frames a√∫n, rellenamos con el √∫ltimo\n",
    "        #while len(self.frames) < self._n_frames:\n",
    "        #    self.frames.append(processed_obs)\n",
    "\n",
    "        # Creamos la observaci√≥n apilada\n",
    "        stacked_obs = np.stack(self.frames, axis=0)\n",
    "        return stacked_obs, total_reward, done, trunk, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = self.env.reset()\n",
    "        processed_obs = process_frame(obs)\n",
    "\n",
    "        self.frames = deque([processed_obs] * self._n_frames, maxlen=self._n_frames)\n",
    "        stacked_obs = np.stack(self.frames, axis=0)\n",
    "        return stacked_obs, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f121874",
   "metadata": {},
   "source": [
    "### 2.4 Creaci√≥n del entorno de entrenamiento\n",
    "\n",
    "Una vez definidos los **wrappers personalizados**, se crea el entorno de entrenamiento aplic√°ndolos de forma modular y estructurada.\n",
    "\n",
    "<blockquote style=\"border-left: 4px solid #009688; background: #e6f9f7; padding: 10px; color: #333;\">\n",
    "üß© <strong>Wrappers aplicados:</strong>\n",
    "<ul style=\"margin-top: 10px;\">\n",
    "  <li><strong>Recompensa personalizada:</strong> ajusta los refuerzos seg√∫n el rendimiento deseado.</li>\n",
    "  <li><strong>Stack de frames:</strong> a√±ade memoria temporal al agente.</li>\n",
    "  <li><strong>Repetici√≥n de acciones:</strong> estabiliza las decisiones reduciendo el ruido de entrada.</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n",
    "A continuaci√≥n, se define la funci√≥n encargada de crear y devolver un entorno completamente configurado para el entrenamiento del agente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "390ddd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mario_env(world, stage, action_type=RIGHT_ONLY, n_frames_stack=4, render_mode=\"rgb_array\"):    \n",
    "    # Crea el entorno base de Super Mario Bros. con el mundo y el nivel especificados.\n",
    "    env = gym_super_mario_bros.make(f\"SuperMarioBros-{world}-{stage}-v0\", apply_api_compatibility=True, render_mode=render_mode)\n",
    "\n",
    "    # Envuelve el entorno en el wrapper del Joystick de NES para poder elegir las acciones.\n",
    "    env = JoypadSpace(env, action_type)\n",
    "\n",
    "    # Envuelve el entorno en los wrappers de CustomStackFrames y CustomReward.\n",
    "    env = CustomReward(env)\n",
    "    env = CustomStackAndRepeat(env, n_frames=n_frames_stack)\n",
    "    \n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7092a3e",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 3. üß† Entrenamiento del agente con Stable Baselines3\n",
    "\n",
    "Para llevar a cabo el entrenamiento del agente, se ha utilizado el algoritmo **PPO (Proximal Policy Optimization)** en combinaci√≥n con una arquitectura basada en **Redes Neuronales Convolucionales (CNNs)**, mediante la librer√≠a üì¶ <code>Stable-Baselines3</code>.\n",
    "\n",
    "<blockquote style=\"border-left: 4px solid #673ab7; background: #f3f0ff; padding: 10px; color: #333;\">\n",
    "üîç <strong>Justificaci√≥n t√©cnica:</strong>\n",
    "<ul style=\"margin-top: 10px;\">\n",
    "  <li><strong>PPO:</strong> algoritmo robusto y eficiente para entornos con observaciones visuales complejas.</li>\n",
    "  <li><strong>CNN:</strong> excelente rendimiento en entornos visuales como Super Mario Bros, donde la entrada es una imagen procesada.</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n",
    "La elecci√≥n concreta de esta arquitectura se detalla con mayor profundidad en la <strong>memoria de la pr√°ctica</strong>, incluyendo an√°lisis comparativos y experimentaci√≥n con distintas configuraciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8fff16",
   "metadata": {},
   "source": [
    "### 3.1 Implementaci√≥n de entornos vectorizados\n",
    "\n",
    "Para mejorar la eficiencia del entrenamiento y aprovechar al m√°ximo los recursos disponibles, se utiliza **vectorizaci√≥n de entornos**. Esto permite ejecutar m√∫ltiples entornos en paralelo, acelerando la recopilaci√≥n de experiencias del agente.\n",
    "\n",
    "<blockquote style=\"border-left: 4px solid #607d8b; background: #f5f7f9; padding: 10px; color: #333;\">\n",
    "‚öôÔ∏è <strong>Procedimiento:</strong>\n",
    "<ul style=\"margin-top: 10px;\">\n",
    "  <li>Se define el n√∫mero de entornos paralelos a lanzar.</li>\n",
    "  <li>Se encapsula la funci√≥n <code>make_env()</code> para permitir su uso en m√∫ltiples procesos.</li>\n",
    "  <li>Se utiliza <code>SubprocVecEnv</code> o <code>DummyVecEnv</code> de <code>Stable-Baselines3</code> seg√∫n las necesidades del sistema.</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n",
    "Esto permite que el agente recopile experiencias de varios episodios simult√°neamente, lo que **reduce significativamente el tiempo total de entrenamiento** y mejora la estabilidad del aprendizaje.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7c18d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\gym\\envs\\registration.py:555: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\gym\\envs\\registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized environment created.\n",
      "Observation space: Box(0.0, 1.0, (4, 84, 84), float32)\n",
      "Action space: Discrete(5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vamos a utilizar la funci√≥n make_vec_env para crear un entorno vectorizado.\n",
    "# Esta funci√≥n crea un entorno vectorizado utilizando el entorno base que hemos creado anteriormente.\n",
    "# El n√∫mero de entornos vectorizados por defect es 4, pero cambiadlo en base a vuestra CPU y analisis de rendimiento.\n",
    "NUM_ENVS = 8\n",
    "\n",
    "env = make_vec_env(\n",
    "    lambda: create_mario_env(WORLD, STAGE, ACTION_TYPE, n_frames_stack=N_FRAMES_STACK, render_mode=\"rgb_array\"),\n",
    "    n_envs=NUM_ENVS,\n",
    "    vec_env_cls=DummyVecEnv,\n",
    "    monitor_dir=\"./mario_monitor_dir/\",\n",
    "    seed=33\n",
    ")\n",
    "\n",
    "print(\"Vectorized environment created.\")\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "print(\"Action space:\", env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ecfce",
   "metadata": {},
   "source": [
    "### 3.2 Creaci√≥n de callbacks durante el entrenamiento\n",
    "\n",
    "Durante el entrenamiento del agente, se utilizan **callbacks personalizados** para monitorizar el progreso y guardar los modelos peri√≥dicamente. Esto permite evitar la p√©rdida de datos y analizar el comportamiento del agente de forma m√°s controlada.\n",
    "\n",
    "<blockquote style=\"border-left: 4px solid #9c27b0; background: #fdf5ff; padding: 10px; color: #333;\">\n",
    "üõ†Ô∏è <strong>Callbacks utilizados:</strong>\n",
    "<ul style=\"margin-top: 10px;\">\n",
    "  <li><strong>TrainAndLogCallback:</strong> guarda el modelo cada cierto n√∫mero de pasos y registra el progreso del entrenamiento.</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n",
    "A continuaci√≥n, se muestra la implementaci√≥n del callback principal utilizado:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d40dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Callback para guardar el modelo y registrar la informaci√≥n durante el entrenamiento.\n",
    "# Este callback se ejecuta cada cierto n√∫mero de pasos y guarda el modelo en la ruta especificada.\n",
    "class TrainAndLogCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, save_path, start_steps=0, verbose=1):\n",
    "        super(TrainAndLogCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "        self.start_steps = start_steps\n",
    "\n",
    "    def _init_callback(self):\n",
    "        # Creamos la carpeta de guardado si no existe.\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Guardamos el modelo cada check_freq pasos.\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            if self.save_path is not None:\n",
    "                self.model.save(os.path.join(self.save_path, \"model_{}\".format(self.n_calls + int(self.start_steps))))\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabea59a",
   "metadata": {},
   "source": [
    "### 3.3 Funciones adicionales\n",
    "\n",
    "Se define una funci√≥n auxiliar llamada <code>linear_schedule()</code>, utilizada para aplicar una **disminuci√≥n lineal del learning rate** a lo largo del entrenamiento. Esta t√©cnica es com√∫n en problemas de aprendizaje por refuerzo y puede aportar varias ventajas clave:\n",
    "\n",
    "<blockquote style=\"border-left: 4px solid #03a9f4; background: #f0faff; padding: 10px; color: #333;\">\n",
    "‚úÖ <strong>Ventajas: </strong>\n",
    "<ul style=\"margin-top: 10px;\">\n",
    "  <li> <strong>Evita sobreentrenamiento:</strong> reduce los ajustes agresivos en etapas finales, estabilizando la pol√≠tica.</li>\n",
    "  <li> <strong>Favorece un aprendizaje r√°pido al inicio:</strong> una tasa alta al principio permite mayor exploraci√≥n.</li>\n",
    "  <li> <strong>Mejora la convergencia:</strong> muchos algoritmos de RL funcionan mejor con <em>learning rate decay</em>.</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n",
    "A continuaci√≥n, se muestra la implementaci√≥n de la funci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0409f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rateDecay(initial_value: float) -> Callable[[float], float]:\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        return progress_remaining * initial_value\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a497c4dd",
   "metadata": {},
   "source": [
    "### 3.4 Entrenamiento de la pol√≠tica\n",
    "\n",
    "Una vez configurado el entorno, las funciones auxiliares y los callbacks, se crea el modelo PPO con los par√°metros deseados y se inicia el proceso de entrenamiento.\n",
    "\n",
    "<blockquote style=\"border-left: 4px solid #4caf50; background: #f4fff4; padding: 10px; color: #333;\">\n",
    "<strong>üèãÔ∏è‚Äç‚ôÇÔ∏è lujo del entrenamiento:</strong>\n",
    "<ul style=\"margin-top: 10px;\">\n",
    "  <li> Se instancia el modelo <code>PPO</code> utilizando una pol√≠tica <code>'CnnPolicy'</code>.</li>\n",
    "  <li> Se utiliza <code>linear_schedule()</code> para disminuir el learning rate progresivamente.</li>\n",
    "  <li> Se integran los callbacks personalizados para evaluar, guardar y registrar el progreso.</li>\n",
    "  <li> Finalizado el entrenamiento, se guarda el modelo y se visualizan los resultados obtenidos.</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n",
    "A continuaci√≥n, se muestra el bloque de c√≥digo para ejecutar el entrenamiento:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f71f0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Modelo PPO inicializado correctamente.\n",
      "Logging to ./mario_logs/PPO_28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 129      |\n",
      "|    ep_rew_mean     | 61.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 128      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 4096     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 265         |\n",
      "|    ep_rew_mean          | 79.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022877544 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 5.66e-06    |\n",
      "|    learning_rate        | 0.000498    |\n",
      "|    loss                 | 2.85        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | 0.000816    |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 239         |\n",
      "|    ep_rew_mean          | 77.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009189925 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.000496    |\n",
      "|    loss                 | 9.36        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | 0.00136     |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 241         |\n",
      "|    ep_rew_mean          | 79.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010128125 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.000494    |\n",
      "|    loss                 | 5.67        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | 0.00237     |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 216         |\n",
      "|    ep_rew_mean          | 79.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009372452 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.000492    |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | 0.00136     |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 204         |\n",
      "|    ep_rew_mean          | 82.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011331933 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.00049     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 170          |\n",
      "|    ep_rew_mean          | 86.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 253          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134136155 |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.48        |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.000488     |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 31.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 148         |\n",
      "|    ep_rew_mean          | 86.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012816029 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.000486    |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.000129   |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 144         |\n",
      "|    ep_rew_mean          | 89.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 328         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012412507 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.000484    |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    value_loss           | 43.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 123         |\n",
      "|    ep_rew_mean          | 84.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017102178 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.000482    |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 114         |\n",
      "|    ep_rew_mean          | 84.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 402         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015913928 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.00048     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | 0.000315    |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 110         |\n",
      "|    ep_rew_mean          | 83.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 438         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015397366 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.000477    |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.000325   |\n",
      "|    value_loss           | 47.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 117         |\n",
      "|    ep_rew_mean          | 86.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 475         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023078963 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.000475    |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | 7.51e-05    |\n",
      "|    value_loss           | 67.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 115         |\n",
      "|    ep_rew_mean          | 87.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 512         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017667279 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.000473    |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0025     |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 121         |\n",
      "|    ep_rew_mean          | 91.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 549         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016971234 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.000471    |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | 0.00219     |\n",
      "|    value_loss           | 70.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 118        |\n",
      "|    ep_rew_mean          | 91.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 587        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01796421 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | 0.439      |\n",
      "|    learning_rate        | 0.000469   |\n",
      "|    loss                 | 19.9       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.00108   |\n",
      "|    value_loss           | 56.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 123         |\n",
      "|    ep_rew_mean          | 96          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 624         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016312454 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.000467    |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.00226     |\n",
      "|    value_loss           | 61.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 118         |\n",
      "|    ep_rew_mean          | 93.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 661         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022240836 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.000465    |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.00224     |\n",
      "|    value_loss           | 66.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 118         |\n",
      "|    ep_rew_mean          | 93.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 698         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017450323 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.000463    |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    value_loss           | 63.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 125         |\n",
      "|    ep_rew_mean          | 97.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 735         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032979216 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.000461    |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00345    |\n",
      "|    value_loss           | 61.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 133        |\n",
      "|    ep_rew_mean          | 99.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 772        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02226137 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.1       |\n",
      "|    explained_variance   | 0.456      |\n",
      "|    learning_rate        | 0.000459   |\n",
      "|    loss                 | 23.7       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.000233  |\n",
      "|    value_loss           | 64.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 132         |\n",
      "|    ep_rew_mean          | 96.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 809         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032778766 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.000457    |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | 0.00123     |\n",
      "|    value_loss           | 59.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 137         |\n",
      "|    ep_rew_mean          | 93.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 846         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024308886 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.000455    |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | 0.00303     |\n",
      "|    value_loss           | 59          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 136         |\n",
      "|    ep_rew_mean          | 93.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 885         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022599442 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.000453    |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.002       |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 142         |\n",
      "|    ep_rew_mean          | 96.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 924         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025797509 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.000451    |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 140         |\n",
      "|    ep_rew_mean          | 95.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 962         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026605686 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.000449    |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.00243     |\n",
      "|    value_loss           | 49.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 143         |\n",
      "|    ep_rew_mean          | 99.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 1000        |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022539947 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.000447    |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 150         |\n",
      "|    ep_rew_mean          | 98.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1037        |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027472839 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.000445    |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    value_loss           | 43          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 153         |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 1075        |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026936864 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.000443    |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | 0.00122     |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 175         |\n",
      "|    ep_rew_mean          | 109         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 1113        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026762024 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.000441    |\n",
      "|    loss                 | 6.36        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 177       |\n",
      "|    ep_rew_mean          | 108       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 1151      |\n",
      "|    total_timesteps      | 126976    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0341741 |\n",
      "|    clip_fraction        | 0.27      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.04     |\n",
      "|    explained_variance   | 0.694     |\n",
      "|    learning_rate        | 0.000439  |\n",
      "|    loss                 | 26.2      |\n",
      "|    n_updates            | 300       |\n",
      "|    policy_gradient_loss | -0.00374  |\n",
      "|    value_loss           | 50.5      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 166         |\n",
      "|    ep_rew_mean          | 106         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 1191        |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032471888 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.996      |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.000437    |\n",
      "|    loss                 | 44.5        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 154         |\n",
      "|    ep_rew_mean          | 102         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 1232        |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024293864 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.971      |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.000434    |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | 0.00677     |\n",
      "|    value_loss           | 60.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 147         |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 1272        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031100592 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.972      |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.000432    |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | 0.00351     |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 141         |\n",
      "|    ep_rew_mean          | 100         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 1312        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027490217 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.892      |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00043     |\n",
      "|    loss                 | 46.3        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | 0.00242     |\n",
      "|    value_loss           | 65.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 149         |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 1352        |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025576811 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.87       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.000428    |\n",
      "|    loss                 | 35.9        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    value_loss           | 65.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 156         |\n",
      "|    ep_rew_mean          | 110         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 1392        |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030118382 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.79       |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.000426    |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | 0.00348     |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 156         |\n",
      "|    ep_rew_mean          | 111         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 1433        |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.065795965 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.79       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.000424    |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 153         |\n",
      "|    ep_rew_mean          | 111         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 1473        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024569152 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.000422    |\n",
      "|    loss                 | 58.3        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 0.0038      |\n",
      "|    value_loss           | 63.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 146         |\n",
      "|    ep_rew_mean          | 106         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 1514        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034406833 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.665      |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00042     |\n",
      "|    loss                 | 50.9        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    value_loss           | 64.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 144         |\n",
      "|    ep_rew_mean          | 106         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1554        |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031927273 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.701      |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.000418    |\n",
      "|    loss                 | 43.5        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | 0.000128    |\n",
      "|    value_loss           | 67.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 154         |\n",
      "|    ep_rew_mean          | 113         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 1593        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034117762 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.717      |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.000416    |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.00695     |\n",
      "|    value_loss           | 60.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 156        |\n",
      "|    ep_rew_mean          | 113        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 1630       |\n",
      "|    total_timesteps      | 176128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03907633 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.729     |\n",
      "|    explained_variance   | 0.448      |\n",
      "|    learning_rate        | 0.000414   |\n",
      "|    loss                 | 21.9       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | 0.00337    |\n",
      "|    value_loss           | 68.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 162         |\n",
      "|    ep_rew_mean          | 118         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 1667        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030984651 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.738      |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.000412    |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.00621     |\n",
      "|    value_loss           | 55.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 158        |\n",
      "|    ep_rew_mean          | 118        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 1704       |\n",
      "|    total_timesteps      | 184320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03073436 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.668     |\n",
      "|    explained_variance   | 0.529      |\n",
      "|    learning_rate        | 0.00041    |\n",
      "|    loss                 | 34.5       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | 0.00047    |\n",
      "|    value_loss           | 59.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 167         |\n",
      "|    ep_rew_mean          | 125         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1741        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055270806 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.651      |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.000408    |\n",
      "|    loss                 | 37.5        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 0.00239     |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 171         |\n",
      "|    ep_rew_mean          | 127         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1778        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045425825 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.694      |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.000406    |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.00467     |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 174       |\n",
      "|    ep_rew_mean          | 125       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 48        |\n",
      "|    time_elapsed         | 1816      |\n",
      "|    total_timesteps      | 196608    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0456246 |\n",
      "|    clip_fraction        | 0.243     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.708    |\n",
      "|    explained_variance   | 0.572     |\n",
      "|    learning_rate        | 0.000404  |\n",
      "|    loss                 | 16.5      |\n",
      "|    n_updates            | 470       |\n",
      "|    policy_gradient_loss | -0.00146  |\n",
      "|    value_loss           | 51.1      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 188         |\n",
      "|    ep_rew_mean          | 136         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1853        |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045363292 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.638      |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.000402    |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 0.00602     |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 189        |\n",
      "|    ep_rew_mean          | 139        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 50         |\n",
      "|    time_elapsed         | 1892       |\n",
      "|    total_timesteps      | 204800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05490429 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.665     |\n",
      "|    explained_variance   | 0.61       |\n",
      "|    learning_rate        | 0.0004     |\n",
      "|    loss                 | 17         |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | 0.00509    |\n",
      "|    value_loss           | 41.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 192         |\n",
      "|    ep_rew_mean          | 143         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 1931        |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038782008 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.576      |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.000398    |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.000927   |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 203        |\n",
      "|    ep_rew_mean          | 153        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 1970       |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03057471 |\n",
      "|    clip_fraction        | 0.189      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.553     |\n",
      "|    explained_variance   | 0.585      |\n",
      "|    learning_rate        | 0.000396   |\n",
      "|    loss                 | 29.3       |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | 0.00279    |\n",
      "|    value_loss           | 49.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 210        |\n",
      "|    ep_rew_mean          | 164        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 2009       |\n",
      "|    total_timesteps      | 217088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04261206 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.594     |\n",
      "|    explained_variance   | 0.667      |\n",
      "|    learning_rate        | 0.000394   |\n",
      "|    loss                 | 15.5       |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | -0.00112   |\n",
      "|    value_loss           | 46.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 199         |\n",
      "|    ep_rew_mean          | 159         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 2048        |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047978148 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.568      |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.000391    |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | 0.000867    |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 210         |\n",
      "|    ep_rew_mean          | 169         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 2086        |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039331727 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.000389    |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    value_loss           | 59.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 210        |\n",
      "|    ep_rew_mean          | 167        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 2124       |\n",
      "|    total_timesteps      | 229376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06491163 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.539     |\n",
      "|    explained_variance   | 0.718      |\n",
      "|    learning_rate        | 0.000387   |\n",
      "|    loss                 | 23.4       |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | 0.00412    |\n",
      "|    value_loss           | 46.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 211         |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 2162        |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030020775 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.503      |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.000385    |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | 0.00126     |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 217         |\n",
      "|    ep_rew_mean          | 168         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 2201        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052031204 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.527      |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.000383    |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | 0.00283     |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 219        |\n",
      "|    ep_rew_mean          | 167        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 2239       |\n",
      "|    total_timesteps      | 241664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04581472 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.504     |\n",
      "|    explained_variance   | 0.723      |\n",
      "|    learning_rate        | 0.000381   |\n",
      "|    loss                 | 10.5       |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | 0.000889   |\n",
      "|    value_loss           | 36.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 216         |\n",
      "|    ep_rew_mean          | 164         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 2277        |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.107415244 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.36       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.000379    |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | 0.0144      |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 250         |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 2315        |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021108758 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0778     |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.000377    |\n",
      "|    loss                 | 1.73        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.000827   |\n",
      "|    value_loss           | 7.87        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 259         |\n",
      "|    ep_rew_mean          | 161         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 2352        |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042229168 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.000375    |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 274         |\n",
      "|    ep_rew_mean          | 163         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 2390        |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038659003 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.425      |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.000373    |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.00575     |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 286         |\n",
      "|    ep_rew_mean          | 160         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 2428        |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025299337 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.451      |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.000371    |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | 0.00204     |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 290        |\n",
      "|    ep_rew_mean          | 162        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 2466       |\n",
      "|    total_timesteps      | 266240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03997404 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.384     |\n",
      "|    explained_variance   | 0.632      |\n",
      "|    learning_rate        | 0.000369   |\n",
      "|    loss                 | 32.7       |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | -0.00216   |\n",
      "|    value_loss           | 65.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 300        |\n",
      "|    ep_rew_mean          | 170        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 66         |\n",
      "|    time_elapsed         | 2503       |\n",
      "|    total_timesteps      | 270336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05692751 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.535     |\n",
      "|    explained_variance   | 0.789      |\n",
      "|    learning_rate        | 0.000367   |\n",
      "|    loss                 | 23.3       |\n",
      "|    n_updates            | 650        |\n",
      "|    policy_gradient_loss | 6.28e-05   |\n",
      "|    value_loss           | 45         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 281         |\n",
      "|    ep_rew_mean          | 176         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 2540        |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040771306 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.458      |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.000365    |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | 0.00209     |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 273        |\n",
      "|    ep_rew_mean          | 180        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 68         |\n",
      "|    time_elapsed         | 2578       |\n",
      "|    total_timesteps      | 278528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03392238 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.458     |\n",
      "|    explained_variance   | 0.806      |\n",
      "|    learning_rate        | 0.000363   |\n",
      "|    loss                 | 27.8       |\n",
      "|    n_updates            | 670        |\n",
      "|    policy_gradient_loss | -0.0038    |\n",
      "|    value_loss           | 48.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 268        |\n",
      "|    ep_rew_mean          | 188        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 2617       |\n",
      "|    total_timesteps      | 282624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05367573 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.349     |\n",
      "|    explained_variance   | 0.815      |\n",
      "|    learning_rate        | 0.000361   |\n",
      "|    loss                 | 13.9       |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.00278   |\n",
      "|    value_loss           | 41.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 256         |\n",
      "|    ep_rew_mean          | 194         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 2655        |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032934844 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.409      |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.000359    |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | 0.00129     |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 271         |\n",
      "|    ep_rew_mean          | 201         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 2694        |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040232956 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.458      |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.000357    |\n",
      "|    loss                 | 7.65        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 258         |\n",
      "|    ep_rew_mean          | 196         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 2731        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048061073 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.423      |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.000355    |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 263        |\n",
      "|    ep_rew_mean          | 201        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 73         |\n",
      "|    time_elapsed         | 2769       |\n",
      "|    total_timesteps      | 299008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04083157 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.393     |\n",
      "|    explained_variance   | 0.818      |\n",
      "|    learning_rate        | 0.000353   |\n",
      "|    loss                 | 17.4       |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | 7.78e-05   |\n",
      "|    value_loss           | 47.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 249        |\n",
      "|    ep_rew_mean          | 200        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 74         |\n",
      "|    time_elapsed         | 2807       |\n",
      "|    total_timesteps      | 303104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03419438 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.398     |\n",
      "|    explained_variance   | 0.845      |\n",
      "|    learning_rate        | 0.00035    |\n",
      "|    loss                 | 31         |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | -0.00282   |\n",
      "|    value_loss           | 42.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 242         |\n",
      "|    ep_rew_mean          | 198         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 2844        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033477303 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.377      |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.000348    |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.000532   |\n",
      "|    value_loss           | 61.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 236         |\n",
      "|    ep_rew_mean          | 200         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 2882        |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032281976 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.407      |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.000346    |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | 0.00736     |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 237        |\n",
      "|    ep_rew_mean          | 203        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 2920       |\n",
      "|    total_timesteps      | 315392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04113188 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.42      |\n",
      "|    explained_variance   | 0.897      |\n",
      "|    learning_rate        | 0.000344   |\n",
      "|    loss                 | 10.9       |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | 0.00186    |\n",
      "|    value_loss           | 25.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 242         |\n",
      "|    ep_rew_mean          | 209         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 2958        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042727303 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.477      |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.000342    |\n",
      "|    loss                 | 8.16        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | 0.00346     |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 242         |\n",
      "|    ep_rew_mean          | 208         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 2996        |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040085044 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.499      |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.00034     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | 0.00589     |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 263       |\n",
      "|    ep_rew_mean          | 211       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 80        |\n",
      "|    time_elapsed         | 3033      |\n",
      "|    total_timesteps      | 327680    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0328665 |\n",
      "|    clip_fraction        | 0.2       |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.469    |\n",
      "|    explained_variance   | 0.887     |\n",
      "|    learning_rate        | 0.000338  |\n",
      "|    loss                 | 17.4      |\n",
      "|    n_updates            | 790       |\n",
      "|    policy_gradient_loss | 0.00477   |\n",
      "|    value_loss           | 35.4      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 269        |\n",
      "|    ep_rew_mean          | 215        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 3070       |\n",
      "|    total_timesteps      | 331776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04371629 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.448     |\n",
      "|    explained_variance   | 0.81       |\n",
      "|    learning_rate        | 0.000336   |\n",
      "|    loss                 | 20.1       |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | 0.00345    |\n",
      "|    value_loss           | 56.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 281        |\n",
      "|    ep_rew_mean          | 219        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 3107       |\n",
      "|    total_timesteps      | 335872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04261288 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.486     |\n",
      "|    explained_variance   | 0.843      |\n",
      "|    learning_rate        | 0.000334   |\n",
      "|    loss                 | 29.3       |\n",
      "|    n_updates            | 810        |\n",
      "|    policy_gradient_loss | 0.00679    |\n",
      "|    value_loss           | 50.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 287         |\n",
      "|    ep_rew_mean          | 223         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 3145        |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060216095 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.452      |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.000332    |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | 0.00292     |\n",
      "|    value_loss           | 46.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 299         |\n",
      "|    ep_rew_mean          | 224         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 3182        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043760568 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.472      |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.00033     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 218         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 3219        |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040624764 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.407      |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.000328    |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    value_loss           | 58.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 293         |\n",
      "|    ep_rew_mean          | 221         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 3257        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032847106 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.397      |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.000326    |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    value_loss           | 58.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 273        |\n",
      "|    ep_rew_mean          | 220        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 3296       |\n",
      "|    total_timesteps      | 356352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03796535 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.488     |\n",
      "|    explained_variance   | 0.863      |\n",
      "|    learning_rate        | 0.000324   |\n",
      "|    loss                 | 17.7       |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | -0.000886  |\n",
      "|    value_loss           | 44.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 271         |\n",
      "|    ep_rew_mean          | 218         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 3335        |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052337125 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.46       |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.000322    |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 272        |\n",
      "|    ep_rew_mean          | 210        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 3375       |\n",
      "|    total_timesteps      | 364544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03363783 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.445     |\n",
      "|    explained_variance   | 0.892      |\n",
      "|    learning_rate        | 0.00032    |\n",
      "|    loss                 | 22         |\n",
      "|    n_updates            | 880        |\n",
      "|    policy_gradient_loss | 0.00155    |\n",
      "|    value_loss           | 37.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 268        |\n",
      "|    ep_rew_mean          | 216        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 90         |\n",
      "|    time_elapsed         | 3414       |\n",
      "|    total_timesteps      | 368640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03780585 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.375     |\n",
      "|    explained_variance   | 0.882      |\n",
      "|    learning_rate        | 0.000318   |\n",
      "|    loss                 | 8.72       |\n",
      "|    n_updates            | 890        |\n",
      "|    policy_gradient_loss | -0.00343   |\n",
      "|    value_loss           | 40.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 279         |\n",
      "|    ep_rew_mean          | 224         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 3452        |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033928216 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.417      |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.000316    |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | 0.00239     |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 228         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 3489        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038572088 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.38       |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.000314    |\n",
      "|    loss                 | 9.92        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    value_loss           | 43.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 292         |\n",
      "|    ep_rew_mean          | 237         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 3527        |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031204037 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.433      |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.000312    |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 300        |\n",
      "|    ep_rew_mean          | 244        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 3564       |\n",
      "|    total_timesteps      | 385024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02896477 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.377     |\n",
      "|    explained_variance   | 0.892      |\n",
      "|    learning_rate        | 0.00031    |\n",
      "|    loss                 | 11         |\n",
      "|    n_updates            | 930        |\n",
      "|    policy_gradient_loss | 0.000902   |\n",
      "|    value_loss           | 37.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 300         |\n",
      "|    ep_rew_mean          | 254         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 3600        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041695774 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.372      |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.000307    |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    value_loss           | 58.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 288        |\n",
      "|    ep_rew_mean          | 257        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 96         |\n",
      "|    time_elapsed         | 3637       |\n",
      "|    total_timesteps      | 393216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04418937 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.291     |\n",
      "|    explained_variance   | 0.83       |\n",
      "|    learning_rate        | 0.000305   |\n",
      "|    loss                 | 8.85       |\n",
      "|    n_updates            | 950        |\n",
      "|    policy_gradient_loss | 0.00345    |\n",
      "|    value_loss           | 44.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 278         |\n",
      "|    ep_rew_mean          | 254         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 3673        |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050897583 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.000303    |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | 0.00304     |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 273         |\n",
      "|    ep_rew_mean          | 249         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 3709        |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020790033 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.227      |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.000301    |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    value_loss           | 41.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 285        |\n",
      "|    ep_rew_mean          | 251        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 99         |\n",
      "|    time_elapsed         | 3745       |\n",
      "|    total_timesteps      | 405504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02460306 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.239     |\n",
      "|    explained_variance   | 0.721      |\n",
      "|    learning_rate        | 0.000299   |\n",
      "|    loss                 | 17.8       |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | 0.00153    |\n",
      "|    value_loss           | 52.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 292        |\n",
      "|    ep_rew_mean          | 254        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 100        |\n",
      "|    time_elapsed         | 3781       |\n",
      "|    total_timesteps      | 409600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02490148 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.253     |\n",
      "|    explained_variance   | 0.741      |\n",
      "|    learning_rate        | 0.000297   |\n",
      "|    loss                 | 43.4       |\n",
      "|    n_updates            | 990        |\n",
      "|    policy_gradient_loss | -0.00234   |\n",
      "|    value_loss           | 48.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 278        |\n",
      "|    ep_rew_mean          | 247        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 101        |\n",
      "|    time_elapsed         | 3817       |\n",
      "|    total_timesteps      | 413696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04599509 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.338     |\n",
      "|    explained_variance   | 0.794      |\n",
      "|    learning_rate        | 0.000295   |\n",
      "|    loss                 | 16.2       |\n",
      "|    n_updates            | 1000       |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    value_loss           | 47.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 269         |\n",
      "|    ep_rew_mean          | 239         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 3852        |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017810825 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.000293    |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | 0.00137     |\n",
      "|    value_loss           | 68          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 272        |\n",
      "|    ep_rew_mean          | 246        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 103        |\n",
      "|    time_elapsed         | 3888       |\n",
      "|    total_timesteps      | 421888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03566729 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.285     |\n",
      "|    explained_variance   | 0.814      |\n",
      "|    learning_rate        | 0.000291   |\n",
      "|    loss                 | 37         |\n",
      "|    n_updates            | 1020       |\n",
      "|    policy_gradient_loss | -0.00751   |\n",
      "|    value_loss           | 60.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 276         |\n",
      "|    ep_rew_mean          | 247         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 3924        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038121637 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.818       |\n",
      "|    learning_rate        | 0.000289    |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 55.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 290        |\n",
      "|    ep_rew_mean          | 263        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 105        |\n",
      "|    time_elapsed         | 3960       |\n",
      "|    total_timesteps      | 430080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03360298 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.305     |\n",
      "|    explained_variance   | 0.717      |\n",
      "|    learning_rate        | 0.000287   |\n",
      "|    loss                 | 35         |\n",
      "|    n_updates            | 1040       |\n",
      "|    policy_gradient_loss | -0.000615  |\n",
      "|    value_loss           | 80.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 261        |\n",
      "|    ep_rew_mean          | 252        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 106        |\n",
      "|    time_elapsed         | 3996       |\n",
      "|    total_timesteps      | 434176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03390497 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.354     |\n",
      "|    explained_variance   | 0.778      |\n",
      "|    learning_rate        | 0.000285   |\n",
      "|    loss                 | 42.8       |\n",
      "|    n_updates            | 1050       |\n",
      "|    policy_gradient_loss | -0.00911   |\n",
      "|    value_loss           | 52.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 250         |\n",
      "|    ep_rew_mean          | 243         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 4032        |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027169406 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.000283    |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00158    |\n",
      "|    value_loss           | 71.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 259        |\n",
      "|    ep_rew_mean          | 251        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 4068       |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04090055 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.292     |\n",
      "|    explained_variance   | 0.771      |\n",
      "|    learning_rate        | 0.000281   |\n",
      "|    loss                 | 21.6       |\n",
      "|    n_updates            | 1070       |\n",
      "|    policy_gradient_loss | -0.000249  |\n",
      "|    value_loss           | 75.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 252         |\n",
      "|    ep_rew_mean          | 244         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 4104        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048750985 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.365      |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.000279    |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00139    |\n",
      "|    value_loss           | 70.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 251         |\n",
      "|    ep_rew_mean          | 240         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 4140        |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030600606 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.000277    |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    value_loss           | 86.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 238        |\n",
      "|    ep_rew_mean          | 233        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 111        |\n",
      "|    time_elapsed         | 4176       |\n",
      "|    total_timesteps      | 454656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04191567 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.273     |\n",
      "|    explained_variance   | 0.799      |\n",
      "|    learning_rate        | 0.000275   |\n",
      "|    loss                 | 21.7       |\n",
      "|    n_updates            | 1100       |\n",
      "|    policy_gradient_loss | -0.00143   |\n",
      "|    value_loss           | 61.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 248         |\n",
      "|    ep_rew_mean          | 243         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 4212        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035714656 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.245      |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.000273    |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00234    |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 290         |\n",
      "|    ep_rew_mean          | 255         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 4248        |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057030935 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.000271    |\n",
      "|    loss                 | 4.62        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 291         |\n",
      "|    ep_rew_mean          | 258         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 4284        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030419871 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.248      |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.000269    |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | 0.00088     |\n",
      "|    value_loss           | 69.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 302         |\n",
      "|    ep_rew_mean          | 267         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 4320        |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020217933 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.244      |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.000267    |\n",
      "|    loss                 | 85.2        |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | 0.00244     |\n",
      "|    value_loss           | 78.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 307         |\n",
      "|    ep_rew_mean          | 270         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 4355        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042627804 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.000264    |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 41.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 312         |\n",
      "|    ep_rew_mean          | 275         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 4391        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027560536 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.000262    |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    value_loss           | 82.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 323       |\n",
      "|    ep_rew_mean          | 287       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 109       |\n",
      "|    iterations           | 118       |\n",
      "|    time_elapsed         | 4427      |\n",
      "|    total_timesteps      | 483328    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0651138 |\n",
      "|    clip_fraction        | 0.146     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.288    |\n",
      "|    explained_variance   | 0.66      |\n",
      "|    learning_rate        | 0.00026   |\n",
      "|    loss                 | 56.8      |\n",
      "|    n_updates            | 1170      |\n",
      "|    policy_gradient_loss | -0.00305  |\n",
      "|    value_loss           | 84.8      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 302         |\n",
      "|    ep_rew_mean          | 278         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 4463        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039026193 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.000258    |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 285         |\n",
      "|    ep_rew_mean          | 285         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 4499        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047949567 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.000256    |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    value_loss           | 72          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 291         |\n",
      "|    ep_rew_mean          | 292         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 4535        |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041280888 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.000254    |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    value_loss           | 69.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 282         |\n",
      "|    ep_rew_mean          | 287         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 4571        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056813583 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.000252    |\n",
      "|    loss                 | 9.1         |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 278        |\n",
      "|    ep_rew_mean          | 286        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 123        |\n",
      "|    time_elapsed         | 4607       |\n",
      "|    total_timesteps      | 503808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03335175 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.286     |\n",
      "|    explained_variance   | 0.594      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31         |\n",
      "|    n_updates            | 1220       |\n",
      "|    policy_gradient_loss | -0.0038    |\n",
      "|    value_loss           | 80.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 279         |\n",
      "|    ep_rew_mean          | 293         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 4643        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030370075 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.255      |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.000248    |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    value_loss           | 74          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 282         |\n",
      "|    ep_rew_mean          | 299         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 4678        |\n",
      "|    total_timesteps      | 512000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030042943 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.000246    |\n",
      "|    loss                 | 8.19        |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | 0.00235     |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 301         |\n",
      "|    ep_rew_mean          | 304         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 4714        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039309867 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.406      |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.000244    |\n",
      "|    loss                 | 6.19        |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 301         |\n",
      "|    ep_rew_mean          | 308         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 4750        |\n",
      "|    total_timesteps      | 520192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040247217 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.399      |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.000242    |\n",
      "|    loss                 | 7.61        |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | 0.00122     |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 324         |\n",
      "|    ep_rew_mean          | 315         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 4786        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032931995 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.36       |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.00024     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | 0.00267     |\n",
      "|    value_loss           | 53.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 316         |\n",
      "|    ep_rew_mean          | 309         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 4821        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026402263 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.426      |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.000238    |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.000329   |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 332         |\n",
      "|    ep_rew_mean          | 310         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 4858        |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022118613 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.376      |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.000236    |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | 0.00117     |\n",
      "|    value_loss           | 56.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 333        |\n",
      "|    ep_rew_mean          | 318        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 131        |\n",
      "|    time_elapsed         | 4897       |\n",
      "|    total_timesteps      | 536576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03358733 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.282     |\n",
      "|    explained_variance   | 0.649      |\n",
      "|    learning_rate        | 0.000234   |\n",
      "|    loss                 | 15.8       |\n",
      "|    n_updates            | 1300       |\n",
      "|    policy_gradient_loss | -5.7e-05   |\n",
      "|    value_loss           | 68.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | 321         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 4936        |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027362764 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.252      |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.000232    |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    value_loss           | 72          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 309         |\n",
      "|    ep_rew_mean          | 309         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 4976        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039768465 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00023     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 307        |\n",
      "|    ep_rew_mean          | 312        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 134        |\n",
      "|    time_elapsed         | 5015       |\n",
      "|    total_timesteps      | 548864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02383485 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.242     |\n",
      "|    explained_variance   | 0.481      |\n",
      "|    learning_rate        | 0.000228   |\n",
      "|    loss                 | 44.7       |\n",
      "|    n_updates            | 1330       |\n",
      "|    policy_gradient_loss | -0.00562   |\n",
      "|    value_loss           | 98.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 295         |\n",
      "|    ep_rew_mean          | 317         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 5055        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029470397 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.000226    |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    value_loss           | 48.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 299         |\n",
      "|    ep_rew_mean          | 325         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 5094        |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040380612 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.000224    |\n",
      "|    loss                 | 48.8        |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 66.3        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 289      |\n",
      "|    ep_rew_mean          | 339      |\n",
      "| time/                   |          |\n",
      "|    fps                  | 109      |\n",
      "|    iterations           | 137      |\n",
      "|    time_elapsed         | 5135     |\n",
      "|    total_timesteps      | 561152   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.04068  |\n",
      "|    clip_fraction        | 0.172    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.3     |\n",
      "|    explained_variance   | 0.768    |\n",
      "|    learning_rate        | 0.000221 |\n",
      "|    loss                 | 10.7     |\n",
      "|    n_updates            | 1360     |\n",
      "|    policy_gradient_loss | -0.00826 |\n",
      "|    value_loss           | 42.7     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 295         |\n",
      "|    ep_rew_mean          | 343         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 5175        |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029700361 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.000219    |\n",
      "|    loss                 | 6.22        |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | 0.000171    |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 308        |\n",
      "|    ep_rew_mean          | 350        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 139        |\n",
      "|    time_elapsed         | 5215       |\n",
      "|    total_timesteps      | 569344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04354696 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.332     |\n",
      "|    explained_variance   | 0.792      |\n",
      "|    learning_rate        | 0.000217   |\n",
      "|    loss                 | 21.6       |\n",
      "|    n_updates            | 1380       |\n",
      "|    policy_gradient_loss | -0.00471   |\n",
      "|    value_loss           | 61.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 311        |\n",
      "|    ep_rew_mean          | 352        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 109        |\n",
      "|    iterations           | 140        |\n",
      "|    time_elapsed         | 5255       |\n",
      "|    total_timesteps      | 573440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03339655 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.323     |\n",
      "|    explained_variance   | 0.719      |\n",
      "|    learning_rate        | 0.000215   |\n",
      "|    loss                 | 24.1       |\n",
      "|    n_updates            | 1390       |\n",
      "|    policy_gradient_loss | -0.00967   |\n",
      "|    value_loss           | 54.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 325         |\n",
      "|    ep_rew_mean          | 373         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 5295        |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028812166 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.000213    |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 321         |\n",
      "|    ep_rew_mean          | 371         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 5334        |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034224145 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.000211    |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 318         |\n",
      "|    ep_rew_mean          | 373         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 5374        |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027436197 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.000209    |\n",
      "|    loss                 | 7.57        |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 320         |\n",
      "|    ep_rew_mean          | 369         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 5415        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025514496 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.000207    |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 59.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 319         |\n",
      "|    ep_rew_mean          | 365         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 5455        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030227708 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.000205    |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    value_loss           | 58.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 314        |\n",
      "|    ep_rew_mean          | 369        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 5494       |\n",
      "|    total_timesteps      | 598016     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04989165 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.326     |\n",
      "|    explained_variance   | 0.481      |\n",
      "|    learning_rate        | 0.000203   |\n",
      "|    loss                 | 9.93       |\n",
      "|    n_updates            | 1450       |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    value_loss           | 32.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 305        |\n",
      "|    ep_rew_mean          | 368        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 147        |\n",
      "|    time_elapsed         | 5533       |\n",
      "|    total_timesteps      | 602112     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02821685 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.318     |\n",
      "|    explained_variance   | 0.451      |\n",
      "|    learning_rate        | 0.000201   |\n",
      "|    loss                 | 59.9       |\n",
      "|    n_updates            | 1460       |\n",
      "|    policy_gradient_loss | -0.00293   |\n",
      "|    value_loss           | 72.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 299         |\n",
      "|    ep_rew_mean          | 363         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 5572        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028867994 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.000199    |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | 0.000397    |\n",
      "|    value_loss           | 47.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 292         |\n",
      "|    ep_rew_mean          | 360         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 5610        |\n",
      "|    total_timesteps      | 610304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025827102 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.000197    |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    value_loss           | 65.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 291         |\n",
      "|    ep_rew_mean          | 359         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 5648        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015880452 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.234      |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.000195    |\n",
      "|    loss                 | 58.7        |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    value_loss           | 63.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 283        |\n",
      "|    ep_rew_mean          | 357        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 151        |\n",
      "|    time_elapsed         | 5685       |\n",
      "|    total_timesteps      | 618496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02407647 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.25      |\n",
      "|    explained_variance   | 0.59       |\n",
      "|    learning_rate        | 0.000193   |\n",
      "|    loss                 | 38.5       |\n",
      "|    n_updates            | 1500       |\n",
      "|    policy_gradient_loss | -0.00667   |\n",
      "|    value_loss           | 69         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 286         |\n",
      "|    ep_rew_mean          | 358         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 5725        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032966763 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.000191    |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 68.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 290        |\n",
      "|    ep_rew_mean          | 364        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 153        |\n",
      "|    time_elapsed         | 5763       |\n",
      "|    total_timesteps      | 626688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02182705 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.351     |\n",
      "|    explained_variance   | 0.873      |\n",
      "|    learning_rate        | 0.000189   |\n",
      "|    loss                 | 9.8        |\n",
      "|    n_updates            | 1520       |\n",
      "|    policy_gradient_loss | -0.00634   |\n",
      "|    value_loss           | 33.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 297        |\n",
      "|    ep_rew_mean          | 372        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 154        |\n",
      "|    time_elapsed         | 5802       |\n",
      "|    total_timesteps      | 630784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05180168 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.291     |\n",
      "|    explained_variance   | 0.552      |\n",
      "|    learning_rate        | 0.000187   |\n",
      "|    loss                 | 8.63       |\n",
      "|    n_updates            | 1530       |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    value_loss           | 12         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 297         |\n",
      "|    ep_rew_mean          | 372         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 5840        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024915421 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.000185    |\n",
      "|    loss                 | 7.05        |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 301         |\n",
      "|    ep_rew_mean          | 373         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 5880        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016707866 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.000183    |\n",
      "|    loss                 | 60.6        |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    value_loss           | 67.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 302       |\n",
      "|    ep_rew_mean          | 372       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 157       |\n",
      "|    time_elapsed         | 5920      |\n",
      "|    total_timesteps      | 643072    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0404437 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.291    |\n",
      "|    explained_variance   | 0.579     |\n",
      "|    learning_rate        | 0.000181  |\n",
      "|    loss                 | 17.3      |\n",
      "|    n_updates            | 1560      |\n",
      "|    policy_gradient_loss | -0.00351  |\n",
      "|    value_loss           | 78.1      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 307        |\n",
      "|    ep_rew_mean          | 377        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 158        |\n",
      "|    time_elapsed         | 5959       |\n",
      "|    total_timesteps      | 647168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02482827 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.276     |\n",
      "|    explained_variance   | 0.532      |\n",
      "|    learning_rate        | 0.000178   |\n",
      "|    loss                 | 7.48       |\n",
      "|    n_updates            | 1570       |\n",
      "|    policy_gradient_loss | -0.00126   |\n",
      "|    value_loss           | 65.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 309         |\n",
      "|    ep_rew_mean          | 383         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 5999        |\n",
      "|    total_timesteps      | 651264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024877267 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.000176    |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 297         |\n",
      "|    ep_rew_mean          | 373         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 6040        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021273889 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.000174    |\n",
      "|    loss                 | 3.49        |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 287         |\n",
      "|    ep_rew_mean          | 363         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 6079        |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026133135 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.255      |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.000172    |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.000384   |\n",
      "|    value_loss           | 98.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 366         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 6120        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036319535 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00017     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 285       |\n",
      "|    ep_rew_mean          | 366       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 108       |\n",
      "|    iterations           | 163       |\n",
      "|    time_elapsed         | 6160      |\n",
      "|    total_timesteps      | 667648    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0413718 |\n",
      "|    clip_fraction        | 0.148     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.277    |\n",
      "|    explained_variance   | 0.544     |\n",
      "|    learning_rate        | 0.000168  |\n",
      "|    loss                 | 25.5      |\n",
      "|    n_updates            | 1620      |\n",
      "|    policy_gradient_loss | -0.00314  |\n",
      "|    value_loss           | 42.8      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 373         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 6199        |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023223871 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.000166    |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    value_loss           | 53.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 277        |\n",
      "|    ep_rew_mean          | 361        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 165        |\n",
      "|    time_elapsed         | 6237       |\n",
      "|    total_timesteps      | 675840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02747505 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.301     |\n",
      "|    explained_variance   | 0.456      |\n",
      "|    learning_rate        | 0.000164   |\n",
      "|    loss                 | 2.7        |\n",
      "|    n_updates            | 1640       |\n",
      "|    policy_gradient_loss | -0.00206   |\n",
      "|    value_loss           | 6.22       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 264         |\n",
      "|    ep_rew_mean          | 335         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 6277        |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016386487 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.000162    |\n",
      "|    loss                 | 63          |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 267         |\n",
      "|    ep_rew_mean          | 337         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 6315        |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032531545 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.257      |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00016     |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | 0.0036      |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 272         |\n",
      "|    ep_rew_mean          | 339         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 6355        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030774359 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.229      |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.000158    |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    value_loss           | 58.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 291         |\n",
      "|    ep_rew_mean          | 338         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 6394        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024508672 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.208      |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.000156    |\n",
      "|    loss                 | 4.9         |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 314         |\n",
      "|    ep_rew_mean          | 346         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 6434        |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028581973 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.257      |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.000154    |\n",
      "|    loss                 | 6.54        |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 313         |\n",
      "|    ep_rew_mean          | 346         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 6473        |\n",
      "|    total_timesteps      | 700416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035611793 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.000152    |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    value_loss           | 35.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 314         |\n",
      "|    ep_rew_mean          | 347         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 6513        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032789037 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00015     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 322         |\n",
      "|    ep_rew_mean          | 366         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 6552        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020182168 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.000148    |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 331         |\n",
      "|    ep_rew_mean          | 380         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 6591        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022211023 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.244      |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.000146    |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 331         |\n",
      "|    ep_rew_mean          | 391         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 6630        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015209111 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.249      |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.000144    |\n",
      "|    loss                 | 5.47        |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.00257    |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 317        |\n",
      "|    ep_rew_mean          | 399        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 176        |\n",
      "|    time_elapsed         | 6671       |\n",
      "|    total_timesteps      | 720896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04294185 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.261     |\n",
      "|    explained_variance   | 0.749      |\n",
      "|    learning_rate        | 0.000142   |\n",
      "|    loss                 | 6.24       |\n",
      "|    n_updates            | 1750       |\n",
      "|    policy_gradient_loss | -0.00967   |\n",
      "|    value_loss           | 21         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 300         |\n",
      "|    ep_rew_mean          | 399         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 6711        |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018925577 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.00014     |\n",
      "|    loss                 | 8.53        |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 298        |\n",
      "|    ep_rew_mean          | 400        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 178        |\n",
      "|    time_elapsed         | 6751       |\n",
      "|    total_timesteps      | 729088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03319594 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.262     |\n",
      "|    explained_variance   | 0.867      |\n",
      "|    learning_rate        | 0.000138   |\n",
      "|    loss                 | 2.92       |\n",
      "|    n_updates            | 1770       |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    value_loss           | 9.26       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 296        |\n",
      "|    ep_rew_mean          | 398        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 179        |\n",
      "|    time_elapsed         | 6790       |\n",
      "|    total_timesteps      | 733184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02221958 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.247     |\n",
      "|    explained_variance   | 0.804      |\n",
      "|    learning_rate        | 0.000135   |\n",
      "|    loss                 | 11.9       |\n",
      "|    n_updates            | 1780       |\n",
      "|    policy_gradient_loss | -0.008     |\n",
      "|    value_loss           | 18.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 296         |\n",
      "|    ep_rew_mean          | 397         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 6829        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021458402 |\n",
      "|    clip_fraction        | 0.0995      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.229      |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.000133    |\n",
      "|    loss                 | 67          |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.000275   |\n",
      "|    value_loss           | 58.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 293         |\n",
      "|    ep_rew_mean          | 392         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 6868        |\n",
      "|    total_timesteps      | 741376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020317607 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.26       |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.000131    |\n",
      "|    loss                 | 6.3         |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.000253   |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 310         |\n",
      "|    ep_rew_mean          | 393         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 6907        |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007313684 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.203      |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.000129    |\n",
      "|    loss                 | 6.82        |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | 0.000846    |\n",
      "|    value_loss           | 63.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 391         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 6947        |\n",
      "|    total_timesteps      | 749568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027179835 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.000127    |\n",
      "|    loss                 | 2.59        |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 329         |\n",
      "|    ep_rew_mean          | 390         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 6986        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018680744 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.243      |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.000125    |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 329        |\n",
      "|    ep_rew_mean          | 387        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 185        |\n",
      "|    time_elapsed         | 7026       |\n",
      "|    total_timesteps      | 757760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01896748 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.234     |\n",
      "|    explained_variance   | 0.875      |\n",
      "|    learning_rate        | 0.000123   |\n",
      "|    loss                 | 1.09       |\n",
      "|    n_updates            | 1840       |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    value_loss           | 25.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 347        |\n",
      "|    ep_rew_mean          | 385        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 186        |\n",
      "|    time_elapsed         | 7066       |\n",
      "|    total_timesteps      | 761856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01662993 |\n",
      "|    clip_fraction        | 0.0741     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.214     |\n",
      "|    explained_variance   | 0.93       |\n",
      "|    learning_rate        | 0.000121   |\n",
      "|    loss                 | 3.7        |\n",
      "|    n_updates            | 1850       |\n",
      "|    policy_gradient_loss | -0.000991  |\n",
      "|    value_loss           | 24.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 357         |\n",
      "|    ep_rew_mean          | 390         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 7107        |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028217774 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.245      |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.000119    |\n",
      "|    loss                 | 2.27        |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 385         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 7148        |\n",
      "|    total_timesteps      | 770048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023340585 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.23       |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 0.000117    |\n",
      "|    loss                 | 3.4         |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 355          |\n",
      "|    ep_rew_mean          | 391          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 189          |\n",
      "|    time_elapsed         | 7189         |\n",
      "|    total_timesteps      | 774144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0152102625 |\n",
      "|    clip_fraction        | 0.0715       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.186       |\n",
      "|    explained_variance   | 0.264        |\n",
      "|    learning_rate        | 0.000115     |\n",
      "|    loss                 | 33.4         |\n",
      "|    n_updates            | 1880         |\n",
      "|    policy_gradient_loss | -0.00018     |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 316         |\n",
      "|    ep_rew_mean          | 393         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 7227        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013198525 |\n",
      "|    clip_fraction        | 0.0834      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.213      |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.000113    |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.0015     |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 312         |\n",
      "|    ep_rew_mean          | 384         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 7265        |\n",
      "|    total_timesteps      | 782336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012726607 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.000111    |\n",
      "|    loss                 | 9.6         |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 319        |\n",
      "|    ep_rew_mean          | 388        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 192        |\n",
      "|    time_elapsed         | 7304       |\n",
      "|    total_timesteps      | 786432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02203171 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.252     |\n",
      "|    explained_variance   | 0.845      |\n",
      "|    learning_rate        | 0.000109   |\n",
      "|    loss                 | 13.6       |\n",
      "|    n_updates            | 1910       |\n",
      "|    policy_gradient_loss | 0.000706   |\n",
      "|    value_loss           | 52.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 341         |\n",
      "|    ep_rew_mean          | 388         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 7341        |\n",
      "|    total_timesteps      | 790528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022120401 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.449      |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.000107    |\n",
      "|    loss                 | 4.17        |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 327         |\n",
      "|    ep_rew_mean          | 386         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 7380        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011487121 |\n",
      "|    clip_fraction        | 0.077       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.239      |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.000105    |\n",
      "|    loss                 | 34.8        |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 319         |\n",
      "|    ep_rew_mean          | 384         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 7418        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009297404 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.166      |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.000103    |\n",
      "|    loss                 | 4.3         |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 325          |\n",
      "|    ep_rew_mean          | 395          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 196          |\n",
      "|    time_elapsed         | 7456         |\n",
      "|    total_timesteps      | 802816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114505775 |\n",
      "|    clip_fraction        | 0.0515       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.175       |\n",
      "|    explained_variance   | 0.346        |\n",
      "|    learning_rate        | 0.000101     |\n",
      "|    loss                 | 9.86         |\n",
      "|    n_updates            | 1950         |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    value_loss           | 41.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 328         |\n",
      "|    ep_rew_mean          | 397         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 7494        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013801479 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.2        |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 9.86e-05    |\n",
      "|    loss                 | 2.81        |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | -0.00721    |\n",
      "|    value_loss           | 5.33        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 324         |\n",
      "|    ep_rew_mean          | 397         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 7533        |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010219614 |\n",
      "|    clip_fraction        | 0.0841      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.216      |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 9.65e-05    |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 330         |\n",
      "|    ep_rew_mean          | 406         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 7571        |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008079496 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.198      |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 9.45e-05    |\n",
      "|    loss                 | 9.04        |\n",
      "|    n_updates            | 1980        |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 299         |\n",
      "|    ep_rew_mean          | 404         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 7609        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028162383 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.233      |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 9.24e-05    |\n",
      "|    loss                 | 4.17        |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    value_loss           | 8.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 293         |\n",
      "|    ep_rew_mean          | 404         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 7648        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012031177 |\n",
      "|    clip_fraction        | 0.0573      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.2        |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 9.04e-05    |\n",
      "|    loss                 | 3.06        |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 292         |\n",
      "|    ep_rew_mean          | 403         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 7687        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011485106 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.218      |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 8.84e-05    |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 290          |\n",
      "|    ep_rew_mean          | 395          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 203          |\n",
      "|    time_elapsed         | 7726         |\n",
      "|    total_timesteps      | 831488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113514755 |\n",
      "|    clip_fraction        | 0.0626       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.189       |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 8.63e-05     |\n",
      "|    loss                 | 6.4          |\n",
      "|    n_updates            | 2020         |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    value_loss           | 42.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 291         |\n",
      "|    ep_rew_mean          | 394         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 7765        |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012852928 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.195      |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 8.43e-05    |\n",
      "|    loss                 | 56.2        |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    value_loss           | 74.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 289         |\n",
      "|    ep_rew_mean          | 390         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 7805        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015855098 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.21       |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 8.22e-05    |\n",
      "|    loss                 | 3.74        |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 285         |\n",
      "|    ep_rew_mean          | 389         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 7844        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009248305 |\n",
      "|    clip_fraction        | 0.0555      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.167      |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 8.02e-05    |\n",
      "|    loss                 | 9.6         |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 395         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 7883        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010074496 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.166      |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 7.81e-05    |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 2060        |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    value_loss           | 9.52        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 286          |\n",
      "|    ep_rew_mean          | 397          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 208          |\n",
      "|    time_elapsed         | 7923         |\n",
      "|    total_timesteps      | 851968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094370805 |\n",
      "|    clip_fraction        | 0.0614       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.174       |\n",
      "|    explained_variance   | 0.897        |\n",
      "|    learning_rate        | 7.61e-05     |\n",
      "|    loss                 | 0.763        |\n",
      "|    n_updates            | 2070         |\n",
      "|    policy_gradient_loss | -0.00855     |\n",
      "|    value_loss           | 3.04         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 403         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 7962        |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004531705 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.171      |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 7.4e-05     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 2080        |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | 411         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 8002        |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007529836 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.172      |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 7.2e-05     |\n",
      "|    loss                 | 0.437       |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    value_loss           | 2.29        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 288          |\n",
      "|    ep_rew_mean          | 412          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 211          |\n",
      "|    time_elapsed         | 8040         |\n",
      "|    total_timesteps      | 864256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064527104 |\n",
      "|    clip_fraction        | 0.0439       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.193       |\n",
      "|    explained_variance   | 0.852        |\n",
      "|    learning_rate        | 6.99e-05     |\n",
      "|    loss                 | 0.942        |\n",
      "|    n_updates            | 2100         |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    value_loss           | 7.32         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 282          |\n",
      "|    ep_rew_mean          | 407          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 212          |\n",
      "|    time_elapsed         | 8079         |\n",
      "|    total_timesteps      | 868352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079133045 |\n",
      "|    clip_fraction        | 0.052        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.198       |\n",
      "|    explained_variance   | 0.785        |\n",
      "|    learning_rate        | 6.79e-05     |\n",
      "|    loss                 | 3.18         |\n",
      "|    n_updates            | 2110         |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    value_loss           | 11           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 279         |\n",
      "|    ep_rew_mean          | 401         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 8117        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018555816 |\n",
      "|    clip_fraction        | 0.0687      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.177      |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 6.58e-05    |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.00139    |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 281         |\n",
      "|    ep_rew_mean          | 397         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 8156        |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011308384 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.192      |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 6.38e-05    |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 2130        |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 280         |\n",
      "|    ep_rew_mean          | 395         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 215         |\n",
      "|    time_elapsed         | 8194        |\n",
      "|    total_timesteps      | 880640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008973544 |\n",
      "|    clip_fraction        | 0.0559      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.163      |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 6.17e-05    |\n",
      "|    loss                 | 5           |\n",
      "|    n_updates            | 2140        |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 284         |\n",
      "|    ep_rew_mean          | 395         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 8234        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012009887 |\n",
      "|    clip_fraction        | 0.0674      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.19       |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 5.97e-05    |\n",
      "|    loss                 | 2.45        |\n",
      "|    n_updates            | 2150        |\n",
      "|    policy_gradient_loss | -0.00992    |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 282         |\n",
      "|    ep_rew_mean          | 393         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 8272        |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006905957 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.149      |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 5.76e-05    |\n",
      "|    loss                 | 3.57        |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 278         |\n",
      "|    ep_rew_mean          | 388         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 8311        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004577171 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.119      |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 5.56e-05    |\n",
      "|    loss                 | 43.5        |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 282         |\n",
      "|    ep_rew_mean          | 392         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 8352        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006050394 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.105      |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 5.35e-05    |\n",
      "|    loss                 | 0.732       |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 305          |\n",
      "|    ep_rew_mean          | 403          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 220          |\n",
      "|    time_elapsed         | 8391         |\n",
      "|    total_timesteps      | 901120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050376914 |\n",
      "|    clip_fraction        | 0.0381       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.112       |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 5.15e-05     |\n",
      "|    loss                 | 61.2         |\n",
      "|    n_updates            | 2190         |\n",
      "|    policy_gradient_loss | -0.000392    |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 302         |\n",
      "|    ep_rew_mean          | 402         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 8430        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005476402 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.127      |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 4.94e-05    |\n",
      "|    loss                 | 3.03        |\n",
      "|    n_updates            | 2200        |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    value_loss           | 6.34        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 300        |\n",
      "|    ep_rew_mean          | 402        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 222        |\n",
      "|    time_elapsed         | 8469       |\n",
      "|    total_timesteps      | 909312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01026484 |\n",
      "|    clip_fraction        | 0.0601     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.144     |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 4.74e-05   |\n",
      "|    loss                 | 33.3       |\n",
      "|    n_updates            | 2210       |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    value_loss           | 35.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 299         |\n",
      "|    ep_rew_mean          | 390         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 8508        |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015603296 |\n",
      "|    clip_fraction        | 0.0417      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.143      |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 4.53e-05    |\n",
      "|    loss                 | 1.84        |\n",
      "|    n_updates            | 2220        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 300         |\n",
      "|    ep_rew_mean          | 385         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 8549        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023813393 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.184      |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 4.33e-05    |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 2230        |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 300          |\n",
      "|    ep_rew_mean          | 383          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 225          |\n",
      "|    time_elapsed         | 8589         |\n",
      "|    total_timesteps      | 921600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071813366 |\n",
      "|    clip_fraction        | 0.043        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.169       |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 4.12e-05     |\n",
      "|    loss                 | 29.8         |\n",
      "|    n_updates            | 2240         |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    value_loss           | 79.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 300         |\n",
      "|    ep_rew_mean          | 381         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 8629        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005277112 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.152      |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 3.92e-05    |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    value_loss           | 52.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 283          |\n",
      "|    ep_rew_mean          | 381          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 227          |\n",
      "|    time_elapsed         | 8668         |\n",
      "|    total_timesteps      | 929792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037222872 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.141       |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 3.72e-05     |\n",
      "|    loss                 | 88.5         |\n",
      "|    n_updates            | 2260         |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 281          |\n",
      "|    ep_rew_mean          | 381          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 228          |\n",
      "|    time_elapsed         | 8706         |\n",
      "|    total_timesteps      | 933888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075363023 |\n",
      "|    clip_fraction        | 0.0484       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.153       |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 3.51e-05     |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 2270         |\n",
      "|    policy_gradient_loss | -0.00847     |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 283          |\n",
      "|    ep_rew_mean          | 386          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 229          |\n",
      "|    time_elapsed         | 8745         |\n",
      "|    total_timesteps      | 937984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036845696 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.131       |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 3.31e-05     |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 2280         |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    value_loss           | 1.93         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 279          |\n",
      "|    ep_rew_mean          | 397          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 230          |\n",
      "|    time_elapsed         | 8783         |\n",
      "|    total_timesteps      | 942080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027482728 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.133       |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 3.1e-05      |\n",
      "|    loss                 | 52.1         |\n",
      "|    n_updates            | 2290         |\n",
      "|    policy_gradient_loss | -0.00081     |\n",
      "|    value_loss           | 25.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 277         |\n",
      "|    ep_rew_mean          | 404         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 8821        |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003454045 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.133      |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 2.9e-05     |\n",
      "|    loss                 | 0.658       |\n",
      "|    n_updates            | 2300        |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    value_loss           | 1.99        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 281          |\n",
      "|    ep_rew_mean          | 409          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 232          |\n",
      "|    time_elapsed         | 8859         |\n",
      "|    total_timesteps      | 950272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028176215 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.138       |\n",
      "|    explained_variance   | 0.923        |\n",
      "|    learning_rate        | 2.69e-05     |\n",
      "|    loss                 | 0.463        |\n",
      "|    n_updates            | 2310         |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    value_loss           | 1.68         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 282          |\n",
      "|    ep_rew_mean          | 409          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 233          |\n",
      "|    time_elapsed         | 8899         |\n",
      "|    total_timesteps      | 954368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037568319 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.156       |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 2.49e-05     |\n",
      "|    loss                 | 3.74         |\n",
      "|    n_updates            | 2320         |\n",
      "|    policy_gradient_loss | -0.00532     |\n",
      "|    value_loss           | 26.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 284         |\n",
      "|    ep_rew_mean          | 414         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 8938        |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014308517 |\n",
      "|    clip_fraction        | 0.0302      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.152      |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 2.28e-05    |\n",
      "|    loss                 | 42          |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 284          |\n",
      "|    ep_rew_mean          | 414          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 235          |\n",
      "|    time_elapsed         | 8977         |\n",
      "|    total_timesteps      | 962560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031840787 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.152       |\n",
      "|    explained_variance   | 0.876        |\n",
      "|    learning_rate        | 2.08e-05     |\n",
      "|    loss                 | 4.84         |\n",
      "|    n_updates            | 2340         |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    value_loss           | 5.55         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 283          |\n",
      "|    ep_rew_mean          | 412          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 236          |\n",
      "|    time_elapsed         | 9017         |\n",
      "|    total_timesteps      | 966656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025014123 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.141       |\n",
      "|    explained_variance   | 0.946        |\n",
      "|    learning_rate        | 1.87e-05     |\n",
      "|    loss                 | 0.769        |\n",
      "|    n_updates            | 2350         |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    value_loss           | 1.39         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 283          |\n",
      "|    ep_rew_mean          | 412          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 237          |\n",
      "|    time_elapsed         | 9056         |\n",
      "|    total_timesteps      | 970752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012500822 |\n",
      "|    clip_fraction        | 0.0092       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.14        |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 1.67e-05     |\n",
      "|    loss                 | 1.54         |\n",
      "|    n_updates            | 2360         |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    value_loss           | 45.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 283          |\n",
      "|    ep_rew_mean          | 412          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 238          |\n",
      "|    time_elapsed         | 9095         |\n",
      "|    total_timesteps      | 974848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022733884 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.137       |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 1.46e-05     |\n",
      "|    loss                 | 0.197        |\n",
      "|    n_updates            | 2370         |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    value_loss           | 1.2          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 281          |\n",
      "|    ep_rew_mean          | 408          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 239          |\n",
      "|    time_elapsed         | 9132         |\n",
      "|    total_timesteps      | 978944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024953345 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.149       |\n",
      "|    explained_variance   | 0.84         |\n",
      "|    learning_rate        | 1.26e-05     |\n",
      "|    loss                 | 0.829        |\n",
      "|    n_updates            | 2380         |\n",
      "|    policy_gradient_loss | -0.00828     |\n",
      "|    value_loss           | 5.95         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 279         |\n",
      "|    ep_rew_mean          | 408         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 9170        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003398333 |\n",
      "|    clip_fraction        | 0.0212      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.155      |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 1.05e-05    |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    value_loss           | 77          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 277          |\n",
      "|    ep_rew_mean          | 404          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 241          |\n",
      "|    time_elapsed         | 9208         |\n",
      "|    total_timesteps      | 987136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017792301 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.144       |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 8.48e-06     |\n",
      "|    loss                 | 1.6          |\n",
      "|    n_updates            | 2400         |\n",
      "|    policy_gradient_loss | -0.00149     |\n",
      "|    value_loss           | 29.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 277          |\n",
      "|    ep_rew_mean          | 402          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 242          |\n",
      "|    time_elapsed         | 9248         |\n",
      "|    total_timesteps      | 991232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024518706 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.15        |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 6.43e-06     |\n",
      "|    loss                 | 4.21         |\n",
      "|    n_updates            | 2410         |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 279          |\n",
      "|    ep_rew_mean          | 407          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 243          |\n",
      "|    time_elapsed         | 9288         |\n",
      "|    total_timesteps      | 995328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010821423 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.137       |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 4.38e-06     |\n",
      "|    loss                 | 48.8         |\n",
      "|    n_updates            | 2420         |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    value_loss           | 21.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 279           |\n",
      "|    ep_rew_mean          | 407           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 244           |\n",
      "|    time_elapsed         | 9328          |\n",
      "|    total_timesteps      | 999424        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074163015 |\n",
      "|    clip_fraction        | 0.00371       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.148        |\n",
      "|    explained_variance   | 0.879         |\n",
      "|    learning_rate        | 2.34e-06      |\n",
      "|    loss                 | 2.82          |\n",
      "|    n_updates            | 2430          |\n",
      "|    policy_gradient_loss | -0.00143      |\n",
      "|    value_loss           | 5.05          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 277          |\n",
      "|    ep_rew_mean          | 405          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 245          |\n",
      "|    time_elapsed         | 9365         |\n",
      "|    total_timesteps      | 1003520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.052807e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.136       |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 2.88e-07     |\n",
      "|    loss                 | 0.485        |\n",
      "|    n_updates            | 2440         |\n",
      "|    policy_gradient_loss | -0.000359    |\n",
      "|    value_loss           | 0.838        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Inicializamos el modelo con PPO y una pol√≠tica MLP\n",
    "model = PPO(\n",
    "    \"CnnPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"./mario_logs/\",\n",
    "    learning_rate=learning_rateDecay(5e-4),\n",
    "    n_steps=512,\n",
    "    policy_kwargs={\"normalize_images\": False}  \n",
    ")\n",
    "\n",
    "print(\"Modelo PPO inicializado correctamente.\")\n",
    "\n",
    "# Inicializamos el callback para guardar el modelo y registrar la informaci√≥n durante el entrenamiento\n",
    "cb = TrainAndLogCallback(check_freq=10000, save_path=\"./mario_models/\", start_steps=0, verbose=1)\n",
    "# eval_callback = EvalCallback(env, eval_freq=10000, deterministic=True, render=False)\n",
    "\n",
    "# N√∫mero de pasos para el entrenamiento\n",
    "total_timesteps = 1e6\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model.learn(total_timesteps=total_timesteps, callback=cb)\n",
    "\n",
    "data = load_results(\"./mario_monitor_dir/\")\n",
    "x, y = ts2xy(data, 'timesteps')\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Episode Reward\")\n",
    "plt.title(\"Recompensa por episodio\")\n",
    "plt.show()\n",
    "\n",
    "# Guardamos el modelo final\n",
    "model.save(\"mario_final_model\")\n",
    "\n",
    "# Cerramos el entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf1022",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 4. üìà Evaluaci√≥n de la pol√≠tica\n",
    "\n",
    "Una vez finalizado el entrenamiento, se procede a **evaluar el rendimiento** del modelo entrenado en un entorno independiente. El objetivo es medir su capacidad para generalizar, sin influencias del entorno de entrenamiento.\n",
    "\n",
    "<blockquote style=\"border-left: 4px solid #2196f3; background: #f0f8ff; padding: 10px; color: #333;\">\n",
    " <strong>üìä M√©tricas obtenidas:</strong>\n",
    "<ul style=\"margin-top: 10px;\">\n",
    "  <li><strong>Recompensa media:</strong> indica el rendimiento promedio por episodio.</li>\n",
    "  <li><strong>Recompensa m√°xima y m√≠nima:</strong> muestran la estabilidad del comportamiento.</li>\n",
    "  <li><strong>N√∫mero de episodios:</strong> define el tama√±o de la muestra evaluada.</li>\n",
    "</ul>\n",
    "</blockquote>\n",
    "\n",
    "La evaluaci√≥n se realiza utilizando funciones proporcionadas por <code>Stable-Baselines3</code> como <code>evaluate_policy()</code>, y puede incluir visualizaci√≥n de episodios o almacenamiento de resultados para an√°lisis posterior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed952776",
   "metadata": {},
   "source": [
    "### 4.1 Visualizaci√≥n del comportamiento del agente\n",
    "\n",
    "En la siguiente celda se realiza una **evaluaci√≥n visual del modelo entrenado**. El agente se ejecuta durante un n√∫mero definido de episodios, y su comportamiento se registra en tiempo real.\n",
    "\n",
    "<blockquote style=\"border-left: 4px solid #00acc1; background: #e0f7fa; padding: 10px; color: #333;\">\n",
    "<strong>üé• Objetivo:</strong> Evaluar y capturar el desempe√±o del agente mediante la creaci√≥n de un <strong>GIF animado</strong> del entorno.\n",
    "</blockquote>\n",
    "\n",
    "El GIF generado ofrece una perspectiva clara del comportamiento aprendido: c√≥mo se mueve el agente, si toma decisiones eficientes y si logra completar el nivel o mejorar su rendimiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e62a452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "c:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:272: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF guardado como 'mario_agent.gif'\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import time\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "env = create_mario_env(WORLD, STAGE, ACTION_TYPE, n_frames_stack=N_FRAMES_STACK, render_mode=\"rgb_array\")\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO.load(\"mario_final_model\")\n",
    "\n",
    "frames = []\n",
    "N_EVAL_EPISODES = 1\n",
    "MAX_STEPS = 600\n",
    "\n",
    "for ep in range(N_EVAL_EPISODES):\n",
    "    obs = env.reset()\n",
    "    done = [False]\n",
    "    steps = 0\n",
    "\n",
    "    while not done[0] and steps < MAX_STEPS:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        frame = env.render(mode=\"rgb_array\")\n",
    "        frames.append(frame)\n",
    "        time.sleep(0.02)\n",
    "        steps += 1\n",
    "\n",
    "env.close()\n",
    "imageio.mimsave(\"mario_agent.gif\", frames, fps=30, loop=0)\n",
    "print(\"GIF guardado como 'mario_agent.gif'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fd3640",
   "metadata": {},
   "source": [
    "### 4.2 Evaluaci√≥n interactiva del agente (visualizaci√≥n en tiempo real)\n",
    "\n",
    "En esta secci√≥n se eval√∫a el modelo entrenado ejecut√°ndolo directamente sobre el entorno, mostrando el resultado **en pantalla en tiempo real**.\n",
    "\n",
    "<blockquote style=\"border-left: 4px solid #03a9f4; background: #e8f7ff; padding: 10px; color: #333;\">\n",
    "<strong>üìà Objetivo:</strong> Observar el comportamiento actual del agente mientras interact√∫a con el entorno, identificando patrones aprendidos, errores y decisiones clave.\n",
    "</blockquote>\n",
    "\n",
    "Esta evaluaci√≥n es √∫til para verificar si el agente ha aprendido una estrategia coherente, as√≠ como para detectar posibles fallos o comportamientos no deseados:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90355473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "c:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Evaluamos el rendimiento del agente en el entorno especificado y mostramos la recompensa media y la desviaci√≥n est√°ndar.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m N_EVAL_EPISODES \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m---> 18\u001b[0m mean_reward, std_reward \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_EVAL_EPISODES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_reward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m +/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstd_reward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m######### EVALUACION CUALITATIVA #########\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Importante! Los wrappers VecEnv devuelven solo done para el fin de estado, no trunk. \u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Del mismo modo, el reset() devuelve solo el estado y no la info.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Reset the environment\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:94\u001b[0m, in \u001b[0;36mevaluate_policy\u001b[1;34m(model, env, n_eval_episodes, deterministic, render, callback, reward_threshold, return_episode_rewards, warn)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (episode_counts \u001b[38;5;241m<\u001b[39m episode_count_targets)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m     88\u001b[0m     actions, states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m     89\u001b[0m         observations,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m     90\u001b[0m         state\u001b[38;5;241m=\u001b[39mstates,\n\u001b[0;32m     91\u001b[0m         episode_start\u001b[38;5;241m=\u001b[39mepisode_starts,\n\u001b[0;32m     92\u001b[0m         deterministic\u001b[38;5;241m=\u001b[39mdeterministic,\n\u001b[0;32m     93\u001b[0m     )\n\u001b[1;32m---> 94\u001b[0m     new_observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     current_rewards \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m rewards\n\u001b[0;32m     96\u001b[0m     current_lengths \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "Cell \u001b[1;32mIn[4], line 27\u001b[0m, in \u001b[0;36mCustomStackAndRepeat.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     24\u001b[0m info \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepeat):\n\u001b[1;32m---> 27\u001b[0m     obs, reward, done, trunk, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     processed_obs \u001b[38;5;241m=\u001b[39m process_frame(obs)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframes\u001b[38;5;241m.\u001b[39mappend(processed_obs)\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m, in \u001b[0;36mCustomReward.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m---> 13\u001b[0m     obs, reward, done, trunk, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo \u001b[38;5;241m=\u001b[39m info\n\u001b[0;32m     15\u001b[0m     processed_img \u001b[38;5;241m=\u001b[39m process_frame(obs)\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\nes_py\\wrappers\\joypad_space.py:74\u001b[0m, in \u001b[0;36mJoypadSpace.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mTake a step using the given action.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# take the step and record the output\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\gym\\wrappers\\time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\gym\\wrappers\\env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\gym\\wrappers\\compatibility.py:108\u001b[0m, in \u001b[0;36mEnvCompatibility.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    105\u001b[0m obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_terminated_truncated_step_api((obs, reward, done, info))\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\gym\\wrappers\\compatibility.py:118\u001b[0m, in \u001b[0;36mEnvCompatibility.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Renders the environment.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m        The rendering of the environment, depending on the render mode\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\nes_py\\nes_env.py:386\u001b[0m, in \u001b[0;36mNESEnv.render\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer \u001b[38;5;241m=\u001b[39m ImageViewer(\n\u001b[0;32m    381\u001b[0m             caption\u001b[38;5;241m=\u001b[39mcaption,\n\u001b[0;32m    382\u001b[0m             height\u001b[38;5;241m=\u001b[39mSCREEN_HEIGHT,\n\u001b[0;32m    383\u001b[0m             width\u001b[38;5;241m=\u001b[39mSCREEN_WIDTH,\n\u001b[0;32m    384\u001b[0m         )\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;66;03m# show the screen on the image viewer\u001b[39;00m\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviewer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscreen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreen\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\nes_py\\_image_viewer.py:148\u001b[0m, in \u001b[0;36mImageViewer.show\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m    140\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyglet\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mImageData(\n\u001b[0;32m    141\u001b[0m     frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    142\u001b[0m     frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m     pitch\u001b[38;5;241m=\u001b[39mframe\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[0;32m    146\u001b[0m )\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# send the image to the window\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_window\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_window\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_window\u001b[38;5;241m.\u001b[39mflip()\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\pyglet\\image\\__init__.py:904\u001b[0m, in \u001b[0;36mImageData.blit\u001b[1;34m(self, x, y, z, width, height)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mblit\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, z\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 904\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_texture\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mblit(x, y, z, width, height)\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\pyglet\\image\\__init__.py:835\u001b[0m, in \u001b[0;36mImageData.get_texture\u001b[1;34m(self, rectangle, force_rectangle)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_texture\u001b[39m(\u001b[38;5;28mself\u001b[39m, rectangle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, force_rectangle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_texture \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    834\u001b[0m             (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_texture\u001b[38;5;241m.\u001b[39m_is_rectangle \u001b[38;5;129;01mand\u001b[39;00m force_rectangle)):\n\u001b[1;32m--> 835\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_texture \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_texture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTexture\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrectangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_rectangle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_texture\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\pyglet\\image\\__init__.py:821\u001b[0m, in \u001b[0;36mImageData.create_texture\u001b[1;34m(self, cls, rectangle, force_rectangle)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a texture containing this image.\u001b[39;00m\n\u001b[0;32m    799\u001b[0m \n\u001b[0;32m    800\u001b[0m \u001b[38;5;124;03mIf the image's dimensions are not powers of 2, a TextureRegion of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m:rtype: cls or cls.region_class\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    820\u001b[0m internalformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_internalformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat)\n\u001b[1;32m--> 821\u001b[0m texture \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternalformat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrectangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_rectangle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchor_x \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchor_y:\n\u001b[0;32m    824\u001b[0m     texture\u001b[38;5;241m.\u001b[39manchor_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchor_x\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\pyglet\\image\\__init__.py:1465\u001b[0m, in \u001b[0;36mTexture.create\u001b[1;34m(cls, width, height, internalformat, rectangle, force_rectangle, min_filter, mag_filter)\u001b[0m\n\u001b[0;32m   1462\u001b[0m     texture_height \u001b[38;5;241m=\u001b[39m _nearest_pow2(height)\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m GLuint()\n\u001b[1;32m-> 1465\u001b[0m \u001b[43mglGenTextures\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1466\u001b[0m glBindTexture(target, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[0;32m   1467\u001b[0m glTexParameteri(target, GL_TEXTURE_MIN_FILTER, min_filter)\n",
      "File \u001b[1;32mc:\\Users\\asahe\\Desktop\\UNIVERSIDAD\\GIR24-25\\MULTIROBOTS\\PracticaRLMario\\.venv\\lib\\site-packages\\pyglet\\gl\\lib.py:87\u001b[0m, in \u001b[0;36merrcheck\u001b[1;34m(result, func, arguments)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mGLException\u001b[39;00m(\u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21merrcheck\u001b[39m(result, func, arguments):\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _debug_gl_trace:\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import time\n",
    "\n",
    "######### EVALUACION CUANTITATIVA #########\n",
    "# Creamos un nuevo entorno para evaluar el agente entrenado.\n",
    "# Este entorno es el mismo que el utilizado para entrenar el agente, pero sin el vectorizado. Vigilad tambien el tipo de renderizado!\n",
    "env = create_mario_env(WORLD, STAGE, ACTION_TYPE, n_frames_stack=N_FRAMES_STACK, render_mode=\"human\")\n",
    "\n",
    "# El entorno debe ser envuelto en un DummyVecEnv para la evaluaci√≥n\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Cargamos el modelo entrenado\n",
    "model = PPO.load(\"mario_final_model\")\n",
    "\n",
    "# Evaluamos el rendimiento del agente en el entorno especificado y mostramos la recompensa media y la desviaci√≥n est√°ndar.\n",
    "N_EVAL_EPISODES = 10\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=N_EVAL_EPISODES, deterministic=True)\n",
    "\n",
    "print(f\"Mean reward: {mean_reward} +/- {std_reward}\")\n",
    "\n",
    "######### EVALUACION CUALITATIVA #########\n",
    "# Importante! Los wrappers VecEnv devuelven solo done para el fin de estado, no trunk. \n",
    "# Del mismo modo, el reset() devuelve solo el estado y no la info.\n",
    "# Tenlo en cuenta para el bucle de evaluaci√≥n.\n",
    "\n",
    "# Implementa un bucle de evaluaci√≥n para analizar el rendimiento del agente entrenado de forma cualitativa.\n",
    "# Consejo: a√±ade time.sleep(0.02) tras renderizar el entorno para que la velocidad de juego sea m√°s lenta y puedas ver mejor el rendimiento del agente.\n",
    "\n",
    "# Reset the environment\n",
    "obs = env.reset()\n",
    "done = False\n",
    "try:\n",
    "    for e in range(N_EVAL_EPISODES):\n",
    "        while not done:\n",
    "            # Obt√©n la acci√≥n del modelo\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            \n",
    "            # Ejecuta la acci√≥n en el entorno y observa el nuevo estado, la recompensa, si ha terminado el episodio y la informaci√≥n adicional.\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            \n",
    "            # Renderiza el entorno para visualizar el juego\n",
    "            env.render()\n",
    "\n",
    "            # Control de la velocidad de juego\n",
    "            time.sleep(0.02)\n",
    "            \n",
    "            if done:\n",
    "                print(\"Episode finished. Resetting environment.\")\n",
    "                obs = env.reset()\n",
    "                done = False\n",
    "        done = False\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting...\")\n",
    "    env.close()\n",
    "    exit()\n",
    "\n",
    "# Cierra el entorno despu√©s de la evaluaci√≥n\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
